#+TITLE: Notes taken from "Source Code Retrieval from Large Software Libraries for Automatic.pdf"
#+LANGUAGE: en
#+OPTIONS: toc:nil h:4 html-postamble:nil html-preamble:t tex:t f:t
#+OPTIONS: prop:("VERSION")
#+HTML_DOCTYPE: <!DOCTYPE html>
#+HTML_HEAD: <link href="http://fonts.googleapis.com/css?family=Roboto+Slab:400,700|Inconsolata:400,700" rel="stylesheet" type="text/css" />
#+HTML_HEAD: <link href="css/style.css" rel="stylesheet" type="text/css" />
#+AUTHOR: Shane Mulligan
#+EMAIL: mailto:mullikine@gmail.com

#+HTML: <div class="outline-2" id="meta">
| *Author* | {{{author}}} ({{{email}}})    |
| *Date*   | {{{time(%Y-%m-%d %H:%M:%S)}}} |
#+HTML: </div>

* External
[[file:~/dump/home/shane/notes2017/uni/cosc/480-project_FY/research/Source%20Code%20Retrieval%20from%20Large%20Software%20Libraries%20for%20Automatic.pdf][SCR from LSL for ABL.pdf]]

#+BEGIN_SRC bash
z "$DUMP$HOME/notes2018/uni/cosc/480-project_FY/research/Source Code Retrieval from Large Software Libraries for Automatic.pdf"
#+END_SRC

* Refactorings
1. parens to def :: '<,'>s/\(.*\)(\(.*\))/\1:: \2/g

* Prp Method in this Dissertation:
** Domain
Large and changing
** Apparatus
1. BF
2. QRM
** Steps
1. Create BF -- Predict Bug Li
2. Describe QR Model
   PRF with SCP
3. Present a RMF

* Ambiguous Terms
1. DR :: dimensionality reduction
1. LT :: Linear Transformation techniques

   Commonly used for DR

   1. LDA :: Linear Discriminant Analysis
   2. PCA :: Principal Component Analysis

* Models
1. QRM :: Query Reformulation Model
2. SBM :: Standard Boolean Model
3. VSM :: Vector Space Model
   BoWM :: Bag of Words Model
4. TFIM :: TF-IDF Models
5. TFIRM :: TF-IDF Retrieval Models
6. UM :: Unigram Model
7. PTM :: Probabilistic Topic Models
8. LM :: Lanugage Model
9. RM :: Retrieval Models
10. LM + BoWM = Unigram Model
11. MHbP Model
12. HDbP Model

* Terms
1. LSL :: Large Software Libraries
2. LSI :: Latent Semantic Indexing
3. ABL :: Automatic Bug Localisation
4. m :: method
5. Hm :: Hybrid method
         Hybrid approach
6. SS :: Search Space
7. M :: Model
8. d :: document
9. Li :: Liklihood
10. Prp :: Proposed by this dissertation
11. PrpA :: Proposed Approach
12. Ralg :: Relevance Algorithm
13. IN :: Information Need
14. BL :: Bug Localisation
15. QR :: Query Reformulation
16. QRM :: Query Reformulation Model
17. SCR :: Source Code Retrieval
    CS :: Code Search
18. Dm :: Dynamic methods
       :: Dynamic methods
19. Sm :: Static methods
          Static approach
21. IRm :: IR methods
22. SBM :: Standard Boolean Model
23. VSM :: Vector Space Model
    BoW :: Bag of Words
    BoWM :: BoW Model
24. BoWa :: BoW assumption
25. DFR :: Divergence From Randomness
26. TFIM :: TF-IDF Models
27. TFIRM :: TF-IDF Retrieval Models
28. BF :: Bayesian framework
    PF :: Probabilistic framework
29. ICN :: Information Content Normalisation
30. DLN :: Document Length Normalisation
31. UM :: Unigram Model
32. PTM :: Probabilistic Topic Models
33. MU :: Mixture of Unigrams
34. pLSA :: Probabilistic Latent Semantic Analysis
35. LDA :: Latent Dirichlet Allocation
36. DR :: Document Retrieval
37. LM :: Lanugage Modelling
38. RM :: Retrieval Models
39. PD :: Probability Distribution
40. P1 :: Probability 1
41. P2 :: Probability 2
42. VH :: Version Histories
43. Pr :: Priors
    PP / PrP :: Prior Probabilities
44. D+M :: Defect + Modification
45. TD :: Temporal Decay
46. DPr :: Document Priors
47. DP :: Document Preparation
48. QR :: Query Reformulation
49. ERF :: Explicit Relevance Feedback
50. PRF :: Pseudo Relevance Feedback
51. SCP :: Spacial Code Proximity
52. rFm :: Roccio's Formula
53. iTh :: Information Theoretic
54. RR :: Retrieval Results
55. RS :: Retrieval Score
56. DRT :: Document Retrieval Techniques
57. MRF / RMF :: Markov Random Field / Random Markov Field
58. Wf :: Word Frequencies
59. IaR :: Interactive Refinement

* Math (get correct symbols)
1. BoW :: ∀x; x ∈ A
   Each d is a vector of Wf.

* Definitions
1. P1
   The probability of having tf occurrences of the term in the document by pure chance.
      As this decreases, the information content of the document (vis-a-vis/in relation with) the term increases.
2. P2
   (1 - P2) is related to the risk of choosing the query term as a discriminative term and works as a normalization factor.

   Can be used as the probability of having one more occurrence of the term in the document, which leads to penalizting the high frequency terms during retrieval.
3. BoWa :: Each word is sampled independantly from the rest of the words in the document.
4. BoW / VSM :: A simplifying representation. Each d is a vector of Wf.
5. LSI :: An early retrieval method.
          Assign greater importance to terms that frequently co-occur in source files.
          Can use to expand a given initial query that consists of a single query term initially.

* Notes
1. Ignore structure but perform well:
   1. LM + BoW = Unigram Model
   2. iTh + BoW = TF-IDF
2. BoWa != BoWM

* Annotations
1. MFR
2. TF-IDF :: Still Competative
3. DRT using BoW
   1. LM :: Uses a PF
   2. DFR :: iTh
4. BoW :: Given a set of documents, allows you to rank them
5. RMF :: Benefit over Traditional BL is IaR
          Exploits SCP
6. SBM :: Gives us Logical Operators in our search queries
          But lacks the notion of ranking.
7. RS :: The higher the RS, the more relevant.
8. Hm :: Combinations of Dm, Sm and IR to narrow down the SS with Dm then use Sm on a smaller SS for better accuracy.

* Uses
1. Bug report is used as a query

* Problem => Solution
1. MRF => IR defect, Loss of inter-term relationships in documents

* IN
1. Concept Localisation
2. Bug Localisation
3. Change Impact Analysis
4. Traceability
5. Link Recovery

* Outline
1. Traditional BL Methods
   1. SCA :: Static Code Analysis
      Need a call graph.
      Can't deal with non-executable files.
   2. Dynamic :: Test cases / Debugger
      Can't make an exhaustive set.
      Also, can't deal with non-executable files.

* Outline
2. IR for BL
3. Organisation of this dissertation
4. Dm
5. Sm
6. IR Methods
7. Hm
8. SBM
9. VSM
10. DFR
    1. Using different PD in IC
       1. P1
       2. P2
    2. TFIM for P1
    3. ICN (P2)
    4. DLN
11. UM
12. PTM
13. MU
14. pLSA
15. LDA
16. DR with PTM
17. IR for BL
18. LM
19. TFIRM
20. Incorporating VH in IR-based BL
21. Estimating D+M -based PrP
22. MHbP Model
23. HDbP Model
24. M the Pr with TD
25. BF for BL
26. DPr
27. Experimental Evaluation
28. DP for BL with VH
29. RR
30. Assisting CS with AQR for BL
31. ERF
32. PRF
33. rFm for ARQ
34. AQR using the RM.
35. The PrpA to QR for SCR
36. Wf